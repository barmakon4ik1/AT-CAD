"""
–§–∞–π–ª: get_flange_en1092_1.py
–ü—É—Ç—å: data/get_flange_en1092_1.py

–û–ø–∏—Å–∞–Ω–∏–µ:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–ª–∞–Ω—Ü–µ–≤ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É EN 1092-1 –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –ü—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ —Ñ–ª–∞–Ω—Ü–µ–≤ —á–µ—Ä–µ–∑ —Ç–∞–±–ª–∏—Ü—É Applicability.
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º Terms, PNxx –∏ Face.
- –ü–æ–¥–¥–µ—Ä–∂–∫—É —Å–ø–µ—Ü-–∫–æ–¥–æ–≤ (32, 34, 35, 36, 37) –¥–ª—è –ø–∞—Ä "—Ñ–ª–∞–Ω–µ—Ü+–±—É—Ä—Ç".
- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤—Å–ø–ª—ã–≤–∞—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –æ–± –æ—à–∏–±–∫–∞—Ö –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è—Ö.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
- pandas, sqlite3
- AT-CAD: windows.at_gui_utils.show_popup
- AT-CAD: locales.at_translations.loc

–ê–≤—Ç–æ—Ä: AT-CAD Dev Team
–î–∞—Ç–∞: 2025-10-12
–í–µ—Ä—Å–∏—è: 2.3
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
"""

import sqlite3
import pandas as pd
import json
from windows.at_gui_utils import show_popup
from locales.at_translations import loc


# === üìò –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–≤–æ–¥–æ–≤ ===
LOCAL_TRANSLATIONS = {
    "applicability_not_found": {
        "ru": "–¢–∞–±–ª–∏—Ü–∞ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ (Applicability) –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.",
        "en": "Applicability table is missing in the database.",
        "de": "Die Tabelle 'Applicability' fehlt in der Datenbank."
    },
    "applicability_empty": {
        "ru": "–¢–∞–±–ª–∏—Ü–∞ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ –ø—É—Å—Ç–∞.",
        "en": "Applicability table is empty.",
        "de": "Die Tabelle 'Applicability' ist leer."
    },
    "type_not_found": {
        "ru": "–¢–∏–ø —Ñ–ª–∞–Ω—Ü–∞ {0} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏.",
        "en": "Flange type {0} not found in applicability table.",
        "de": "Flanschtyp {0} wurde in der Anwendungstabelle nicht gefunden."
    },
    "pn_not_found": {
        "ru": "–î–∞–≤–ª–µ–Ω–∏–µ PN{0} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏.",
        "en": "Pressure PN{0} not found in applicability table.",
        "de": "Druck PN{0} wurde in der Anwendungstabelle nicht gefunden."
    },
    "not_applicable": {
        "ru": "–î–ª—è —Ñ–ª–∞–Ω—Ü–∞ —Ç–∏–ø–∞ {0} –ø—Ä–∏ PN{1} –∏ DN{2} —Å—Ç–∞–Ω–¥–∞—Ä—Ç –Ω–µ –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ.",
        "en": "Flange type {0} with PN{1} and DN{2} is not applicable according to the standard.",
        "de": "Der Flanschtyp {0} mit PN{1} und DN{2} ist gem√§√ü Norm nicht anwendbar."
    },
    "no_dimensions": {
        "ru": "–î–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ñ–ª–∞–Ω—Ü–∞ —Ä–∞–∑–º–µ—Ä—ã –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è.",
        "en": "Dimensions are not defined for this flange. Use manufacturer data.",
        "de": "Abmessungen f√ºr diesen Flansch sind nicht definiert. Verwenden Sie Herstellerangaben."
    },
    "error": {
        "ru": "–û—à–∏–±–∫–∞",
        "en": "Error",
        "de": "Fehler"
    },
    "info": {
        "ru": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
        "en": "Information",
        "de": "Information"
    },
    "success": {
        "ru": "–£—Å–ø–µ—Ö",
        "en": "Success",
        "de": "Erfolg"
    }
}

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
loc.register_translations(LOCAL_TRANSLATIONS)


def _to_int_safe(x):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ —Ü–µ–ª–æ–º—É —á–∏—Å–ª—É."""
    try:
        return int(str(x).strip())
    except Exception:
        return 0


def get_flange_en1092_1(params, db_path="en1092-1.db", verbose: bool = False):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–ª–∞–Ω—Ü–∞ –ø–æ EN 1092-1 –∏–∑ SQLite-–±–∞–∑—ã.

    Args:
        params (dict): –í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
            {
              "type": "11",   # —Ç–∏–ø —Ñ–ª–∞–Ω—Ü–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä 01, 11, 21 –∏ —Ç.–ø.)
              "face": "B1",   # —Ñ–æ—Ä–º–∞ —É–ø–ª–æ—Ç–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏
              "DN": "100",    # –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã–π –¥–∏–∞–º–µ—Ç—Ä
              "PN": "16"      # –Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ
            }
        db_path (str): –ø—É—Ç—å –∫ SQLite –±–∞–∑–µ
        verbose (bool): –≤—ã–≤–æ–¥–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–Ω—Å–æ–ª—å

    Returns:
        dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ —Ñ–ª–∞–Ω—Ü–∞ –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ.
    """
    conn = sqlite3.connect(db_path)
    try:
        type_code = str(params.get("type") or "").strip()
        face_code = str(params.get("face") or "").strip()
        dn_value = str(params.get("DN") or "").strip()
        pn_value = str(params.get("PN") or "").strip()
        pn_table = f"PN{pn_value}"

        result = {"input": params, "data": {}}

        # === 1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ ===
        try:
            applicability_df = pd.read_sql_query("SELECT * FROM Applicability", conn)
            if applicability_df.empty:
                show_popup(loc.get("applicability_empty", "–¢–∞–±–ª–∏—Ü–∞ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ –ø—É—Å—Ç–∞"),
                           title=loc.get("error"), popup_type="error")
                result["error"] = "Applicability table is empty"
                return result

            # –ü—Ä–∏–≤–æ–¥–∏–º —Å—Ç–æ–ª–±—Ü—ã –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –≤–∏–¥—É
            applicability_df.columns = [str(c).strip() for c in applicability_df.columns]
            applicability_df["Typ"] = applicability_df["Typ"].astype(str).str.strip()
            applicability_df["PN"] = applicability_df["PN"].astype(str).str.strip()

            # --- –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ ---
            # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–∞—Ä—ã (02 –∏ 35, 04 –∏ 36 –∏ —Ç.–ø.)
            type_aliases = {
                "02": ["35", "32", "36", "37"],
                "35": ["02", "32", "36", "37"],
                "04": ["34"],
                "34": ["04"],
                "12": ["13"],
                "13": ["12"],
            }

            all_types_to_check = [type_code] + type_aliases.get(type_code, [])
            pn_str = str(pn_value)

            # --- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ PN ---
            pn_filtered = applicability_df[applicability_df["PN"] == pn_str]

            if pn_filtered.empty:
                show_popup(
                    loc.get("pn_not_found", "–î–∞–≤–ª–µ–Ω–∏–µ PN{0} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏", pn_value),
                    title=loc.get("error"), popup_type="error"
                )
                result["error"] = f"PN{pn_value} not found in Applicability"
                return result

            # --- –ü–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å—Ç—Ä–æ–∫–∏ –ø–æ —á–∞—Å—Ç–∏ —Ç–∏–ø–∞ ---
            matched_rows = pn_filtered[
                pn_filtered["Typ"].apply(
                    lambda t: any(sub in t for sub in all_types_to_check)
                )
            ]

            if matched_rows.empty:
                show_popup(
                    loc.get("type_not_found",
                            "–¢–∏–ø —Ñ–ª–∞–Ω—Ü–∞ {0} (–∏–ª–∏ –µ–≥–æ –∞–Ω–∞–ª–æ–≥–∏ {1}) –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ –ø—Ä–∏ PN{2}",
                            type_code, ", ".join(all_types_to_check), pn_value),
                    title=loc.get("error"), popup_type="error"
                )
                result["error"] = f"Type {type_code} (aliases {all_types_to_check}) with PN {pn_value} not found"
                return result

            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É
            row = matched_rows.iloc[0].to_dict()

            # --- –ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–∫–∏ DN ---
            dn_col = None
            for col in row.keys():
                if str(dn_value).strip() == str(col).strip():
                    dn_col = col
                    break

            if not dn_col:
                show_popup(
                    loc.get("dn_not_found", "–î–∏–∞–º–µ—Ç—Ä DN{0} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏", dn_value),
                    title=loc.get("error"), popup_type="error"
                )
                result["error"] = f"DN{dn_value} column not found in Applicability"
                return result

            appl_value = row[dn_col]
            appl_value = int(appl_value) if appl_value not in (None, "", "NaN") else 0

            if appl_value == 0:
                show_popup(
                    loc.get("not_applicable",
                            "–§–ª–∞–Ω–µ—Ü {0} (–∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç—ã {1}) –ø—Ä–∏ PN{2} –∏ DN{3} –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è",
                            type_code, ", ".join(all_types_to_check), pn_value, dn_value),
                    title=loc.get("info"), popup_type="info"
                )
                result["error"] = f"Type {type_code} PN{pn_value} DN{dn_value} not applicable"
                return result

            if verbose:
                print(
                    f"‚úÖ –ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞: Typ={type_code} (–≤–æ–∑–º–æ–∂–Ω—ã–µ {all_types_to_check}), PN={pn_value}, DN={dn_value}")

        except Exception as e:
            show_popup(
                loc.get("applicability_error", "–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏: {0}", e),
                title=loc.get("error"), popup_type="error"
            )
            result["error"] = f"Applicability check failed: {e}"
            return result

        # === 2Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã ===
        terms_df = pd.read_sql_query("SELECT * FROM Terms", conn)
        if terms_df.empty:
            show_popup("–¢–∞–±–ª–∏—Ü–∞ Terms –ø—É—Å—Ç–∞ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.", title=loc.get("error"))
            return result

        row_id_col = terms_df.columns[0]

        def _find_terms_row(code):
            mask = terms_df[row_id_col].astype(str).str.strip() == str(code).strip()
            if mask.any():
                return terms_df[mask].iloc[0].to_dict()
            return {}

        terms_type_row = _find_terms_row(type_code)
        terms_face_row = _find_terms_row(face_code)

        fields = [c for c in terms_df.columns if c != row_id_col]

        # --- PNxx
        pn_row = {}
        try:
            pn_df = pd.read_sql_query(f"SELECT * FROM '{pn_table}'", conn)
            if "DN" in pn_df.columns:
                pn_df["DN"] = pn_df["DN"].astype(str).str.strip()
                match = pn_df[pn_df["DN"] == dn_value]
                if not match.empty:
                    pn_row = {k.strip(): v for k, v in match.iloc[0].to_dict().items() if pd.notna(v)}
        except Exception as e:
            if verbose:
                print("‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PN —Ç–∞–±–ª–∏—Ü—ã:", e)

        # --- Face
        face_row = {}
        try:
            face_df = pd.read_sql_query("SELECT * FROM Face", conn)
            if "DN" in face_df.columns:
                face_df["DN"] = face_df["DN"].astype(str).str.strip()
                match = face_df[face_df["DN"] == dn_value]
                if not match.empty:
                    face_row = {k.strip(): v for k, v in match.iloc[0].to_dict().items() if pd.notna(v)}
        except Exception as e:
            if verbose:
                print("‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Face —Ç–∞–±–ª–∏—Ü—ã:", e)

        specials = {32, 34, 35, 36, 37}
        final = {}

        # === 3Ô∏è‚É£ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ===
        for col in fields:
            field_name = col.strip()
            if not field_name:
                continue

            type_mark = _to_int_safe(terms_type_row.get(col, 0))
            face_mark = _to_int_safe(terms_face_row.get(col, 0))

            if face_mark in specials:
                eff_mark = face_mark
            elif type_mark in specials:
                eff_mark = type_mark
            elif 2 in (face_mark, type_mark):
                eff_mark = 2
            elif 1 in (face_mark, type_mark):
                eff_mark = 1
            else:
                eff_mark = 0

            if eff_mark == 0:
                continue

            restricted = (eff_mark == 2)
            value, source = None, None

            # –°–ø–µ—Ü-–∫–æ–¥—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, _36)
            if eff_mark in specials:
                suffix = f"_{eff_mark}"
                field_special = field_name + suffix
                for src, data in [(pn_table, pn_row), ("Face", face_row)]:
                    if field_special in data and data[field_special]:
                        value, source = data[field_special], src
                        break
                    if field_name in data and data[field_name]:
                        value, source = data[field_name], src
                        break
            else:
                for src, data in [(pn_table, pn_row), ("Face", face_row)]:
                    if field_name in data and data[field_name]:
                        value, source = data[field_name], src
                        break

            if value is not None:
                final[field_name] = {"value": str(value), "restricted": restricted, "source": source}
            elif verbose:
                print(f"‚ö†Ô∏è –ü–æ–ª–µ {field_name} –æ—Ç–º–µ—á–µ–Ω–æ –≤ Terms, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ PNxx/Face")

        result["data"] = final

        if not final:
            show_popup(loc.get("no_dimensions"), title=loc.get("info"), popup_type="info")

        return result

    finally:
        conn.close()


# === üîß –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    params = {"type": "11", "face": "B1", "DN": "100", "PN": "16"}
    result = get_flange_en1092_1(params, db_path="en1092-1.db", verbose=True)

    print(f'EN1092-1 /{params["type"]} / {params["face"]} / {params["DN"]} / {params["PN"]}')
    h2_value = result["data"]["H2"]["value"]
    print(f'H2 = {h2_value}')

    # print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢ ===")
    # print(json.dumps(result, ensure_ascii=False, indent=2))


